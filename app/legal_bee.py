import os
import re
from dotenv import load_dotenv
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
from langchain_core.output_parsers import StrOutputParser
from langchain_pinecone import PineconeVectorStore
from langchain_huggingface import HuggingFaceEmbeddings
from operator import itemgetter
from langdetect import detect, LangDetectException
from typing import List, Dict, Tuple, Set, Any
from langchain_core.documents import Document
from langchain_openai import ChatOpenAI
from pydantic import SecretStr
import logging
import numpy as np

load_dotenv()

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# HuggingFace embeddings
emb = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

# Pinecone retriever setup
index_name = os.environ["PINECONE_INDEX_NAME"]
vectorstore = PineconeVectorStore(index_name=index_name, embedding=emb, namespace="")

# OpenRouter LLM
OPENROUTER_API_KEY = os.environ["OPENROUTER_API_KEY"]
llm = ChatOpenAI(
    model="openai/gpt-4o-mini",
    temperature=0,
    api_key=SecretStr(OPENROUTER_API_KEY),
    base_url="https://openrouter.ai/api/v1"
)

# Enhanced language detection with confidence scoring
def detect_language_with_confidence(query: str) -> Tuple[str, float]:
    """Enhanced language detection with confidence scoring"""
    try:
        detected = detect(query)
        bengali_chars = len(re.findall(r'[\u0980-\u09FF]', query))
        english_chars = len(re.findall(r'[a-zA-Z]', query))
        total_chars = bengali_chars + english_chars
        
        if total_chars == 0:
            return 'en', 0.5
        
        bengali_ratio = bengali_chars / total_chars
        english_ratio = english_chars / total_chars
        
        if bengali_ratio > 0.6:
            return 'bn', bengali_ratio
        elif english_ratio > 0.6:
            return 'en', english_ratio
        else:
            return detected, 0.7
    except LangDetectException:
        bengali_chars = len(re.findall(r'[\u0980-\u09FF]', query))
        english_chars = len(re.findall(r'[a-zA-Z]', query))
        if bengali_chars > english_chars:
            return 'bn', 0.6
        else:
            return 'en', 0.6

# Legal domain keyword extraction
LEGAL_KEYWORDS_EN = {
    'criminal': ['murder', 'theft', 'fraud', 'assault', 'criminal', 'police', 'fir', 'charge', 'arrest', 'bail', 'trial'],
    'civil': ['contract', 'property', 'land', 'dispute', 'damages', 'civil', 'suit', 'decree', 'injunction'],
    'family': ['marriage', 'divorce', 'custody', 'alimony', 'family', 'wife', 'husband', 'child', 'adoption'],
    'banking': ['bank', 'loan', 'defaulter', 'account', 'deposit', 'credit', 'banking', 'foreclosure', 'recovery'],
    'election': ['election', 'vote', 'candidate', 'officer', 'commission', 'ballot', 'petition'],
    'labor': ['worker', 'employee', 'salary', 'wage', 'labor', 'employment', 'job', 'termination', 'compensation'],
    'cyber': ['internet', 'online', 'digital', 'cyber', 'computer', 'data', 'hacking', 'privacy', 'defamation'],
    'constitutional': ['constitution', 'rights', 'fundamental', 'writ', 'petition', 'supreme court'],
    'administrative': ['administrative', 'tribunal', 'service', 'government', 'order', 'appeal'],
    'environmental': ['environment', 'pollution', 'forest', 'wildlife', 'conservation']
}

LEGAL_KEYWORDS_BN = {
    'criminal': ['à¦–à§à¦¨', 'à¦šà§à¦°à¦¿', 'à¦ªà§à¦°à¦¤à¦¾à¦°à¦£à¦¾', 'à¦†à¦•à§à¦°à¦®à¦£', 'à¦«à§Œà¦œà¦¦à¦¾à¦°à¦¿', 'à¦ªà§à¦²à¦¿à¦¶', 'à¦®à¦¾à¦®à¦²à¦¾', 'à¦—à§à¦°à§‡à¦«à¦¤à¦¾à¦°', 'à¦œà¦¾à¦®à¦¿à¦¨', 'à¦¬à¦¿à¦šà¦¾à¦°'],
    'civil': ['à¦šà§à¦•à§à¦¤à¦¿', 'à¦¸à¦®à§à¦ªà¦¤à§à¦¤à¦¿', 'à¦œà¦®à¦¿', 'à¦¬à¦¿à¦°à§‹à¦§', 'à¦•à§à¦·à¦¤à¦¿à¦ªà§‚à¦°à¦£', 'à¦¦à§‡à¦“à¦¯à¦¼à¦¾à¦¨à¦¿', 'à¦®à¦¾à¦®à¦²à¦¾', 'à¦¡à¦¿à¦•à§à¦°à¦¿', 'à¦¨à¦¿à¦·à§‡à¦§à¦¾à¦œà§à¦à¦¾'],
    'family': ['à¦¬à¦¿à¦¬à¦¾à¦¹', 'à¦¤à¦¾à¦²à¦¾à¦•', 'à¦…à¦­à¦¿à¦­à¦¾à¦¬à¦•à¦¤à§à¦¬', 'à¦­à¦°à¦£à¦ªà§‹à¦·à¦£', 'à¦ªà¦¾à¦°à¦¿à¦¬à¦¾à¦°à¦¿à¦•', 'à¦¸à§à¦¤à§à¦°à§€', 'à¦¸à§à¦¬à¦¾à¦®à§€', 'à¦¸à¦¨à§à¦¤à¦¾à¦¨', 'à¦¦à¦¤à§à¦¤à¦•'],
    'banking': ['à¦¬à§à¦¯à¦¾à¦‚à¦•', 'à¦‹à¦£', 'à¦–à§‡à¦²à¦¾à¦ªà¦¿', 'à¦…à§à¦¯à¦¾à¦•à¦¾à¦‰à¦¨à§à¦Ÿ', 'à¦†à¦®à¦¾à¦¨à¦¤', 'à¦‹à¦£', 'à¦¬à§à¦¯à¦¾à¦‚à¦•à¦¿à¦‚', 'à¦«à§‹à¦°à¦•à§à¦²à§‹à¦œà¦¾à¦°', 'à¦†à¦¦à¦¾à¦¯à¦¼'],
    'election': ['à¦¨à¦¿à¦°à§à¦¬à¦¾à¦šà¦¨', 'à¦­à§‹à¦Ÿ', 'à¦ªà§à¦°à¦¾à¦°à§à¦¥à§€', 'à¦•à¦°à§à¦®à¦•à¦°à§à¦¤à¦¾', 'à¦•à¦®à¦¿à¦¶à¦¨', 'à¦¬à§à¦¯à¦¾à¦²à¦Ÿ', 'à¦ªà¦¿à¦Ÿà¦¿à¦¶à¦¨'],
    'labor': ['à¦¶à§à¦°à¦®à¦¿à¦•', 'à¦•à¦°à§à¦®à¦šà¦¾à¦°à§€', 'à¦¬à§‡à¦¤à¦¨', 'à¦®à¦œà§à¦°à¦¿', 'à¦¶à§à¦°à¦®', 'à¦šà¦¾à¦•à¦°à¦¿', 'à¦•à¦¾à¦œ', 'à¦¬à¦°à¦–à¦¾à¦¸à§à¦¤', 'à¦•à§à¦·à¦¤à¦¿à¦ªà§‚à¦°à¦£'],
    'cyber': ['à¦‡à¦¨à§à¦Ÿà¦¾à¦°à¦¨à§‡à¦Ÿ', 'à¦…à¦¨à¦²à¦¾à¦‡à¦¨', 'à¦¡à¦¿à¦œà¦¿à¦Ÿà¦¾à¦²', 'à¦¸à¦¾à¦‡à¦¬à¦¾à¦°', 'à¦•à¦®à§à¦ªà¦¿à¦‰à¦Ÿà¦¾à¦°', 'à¦¤à¦¥à§à¦¯', 'à¦¹à§à¦¯à¦¾à¦•à¦¿à¦‚', 'à¦—à§‹à¦ªà¦¨à§€à¦¯à¦¼à¦¤à¦¾', 'à¦®à¦¾à¦¨à¦¹à¦¾à¦¨à¦¿'],
    'constitutional': ['à¦¸à¦‚à¦¬à¦¿à¦§à¦¾à¦¨', 'à¦…à¦§à¦¿à¦•à¦¾à¦°', 'à¦®à§Œà¦²à¦¿à¦•', 'à¦°à¦¿à¦Ÿ', 'à¦ªà¦¿à¦Ÿà¦¿à¦¶à¦¨', 'à¦¸à§à¦ªà§à¦°à¦¿à¦® à¦•à§‹à¦°à§à¦Ÿ'],
    'administrative': ['à¦ªà§à¦°à¦¶à¦¾à¦¸à¦¨à¦¿à¦•', 'à¦Ÿà§à¦°à¦¾à¦‡à¦¬à§à¦¯à§à¦¨à¦¾à¦²', 'à¦¸à¦¾à¦°à§à¦­à¦¿à¦¸', 'à¦¸à¦°à¦•à¦¾à¦°', 'à¦†à¦¦à§‡à¦¶', 'à¦†à¦ªà¦¿à¦²'],
    'environmental': ['à¦ªà¦°à¦¿à¦¬à§‡à¦¶', 'à¦¦à§‚à¦·à¦£', 'à¦¬à¦¨', 'à¦¬à¦¨à§à¦¯à¦ªà§à¦°à¦¾à¦£à§€', 'à¦¸à¦‚à¦°à¦•à§à¦·à¦£']
}

def extract_legal_domain(query: str, lang: str) -> List[str]:
    """Extract legal domains from query"""
    keywords = LEGAL_KEYWORDS_BN if lang == 'bn' else LEGAL_KEYWORDS_EN
    query_lower = query.lower()
    
    domains = []
    for domain, words in keywords.items():
        if any(word in query_lower for word in words):
            domains.append(domain)
    
    return domains if domains else ['general']

# Advanced query expansion
def expand_query_terms(query: str, lang: str) -> List[str]:
    """Expand query with related legal terms"""
    expansions = []
    domains = extract_legal_domain(query, lang)
    
    for domain in domains:
        if domain in LEGAL_KEYWORDS_EN:
            if lang == 'bn':
                expansions.extend(LEGAL_KEYWORDS_BN.get(domain, [])[:3])
            else:
                expansions.extend(LEGAL_KEYWORDS_EN.get(domain, [])[:3])
    
    return list(set(expansions))

# Enhanced translation with legal context
ENHANCED_TRANSLATE_TO_ENGLISH_PROMPT = ChatPromptTemplate.from_template(
    """You are a legal translation expert. Translate this Bengali legal query to English while preserving all legal nuances and terminology.

Bengali Query: {query}
Legal Domain: {domain}

Precise English Translation:"""
)

ENHANCED_TRANSLATE_TO_BENGALI_PROMPT = ChatPromptTemplate.from_template(
    """You are a legal translation expert. Translate this English legal query to Bengali while preserving all legal nuances and terminology.

English Query: {query}
Legal Domain: {domain}

Precise Bengali Translation:"""
)

def enhanced_translate_query(query: str, source_lang: str, target_lang: str) -> str:
    """Enhanced translation with legal domain awareness"""
    if source_lang == target_lang:
        return query
    
    try:
        domains = extract_legal_domain(query, source_lang)
        domain_context = ', '.join(domains)
        
        if target_lang == 'en' and source_lang == 'bn':
            chain = ENHANCED_TRANSLATE_TO_ENGLISH_PROMPT | llm | StrOutputParser()
            return chain.invoke({"query": query, "domain": domain_context}).strip()
        elif target_lang == 'bn' and source_lang == 'en':
            chain = ENHANCED_TRANSLATE_TO_BENGALI_PROMPT | llm | StrOutputParser()
            return chain.invoke({"query": query, "domain": domain_context}).strip()
        else:
            return query
    except Exception as e:
        logger.warning(f"Enhanced translation failed: {e}")
        return query

# Multi-strategy retrieval system
class MultiStrategyRetriever:
    def __init__(self, vectorstore, k=15, min_score=0.65):
        self.vectorstore = vectorstore
        self.k = k
        self.min_score = min_score
    
    def hybrid_search(self, query: str, lang: str) -> List[Document]:
        """Hybrid search with lang filter"""
        all_results = []
        
        # Lang filter
        lang_filter = {"lang": "bn / en"} if lang == 'bn' else {"lang": "en / bn"}
        
        def perform_search(search_query: str, strategy: str, score_multiplier: float = 1.0):
            try:
                search_kwargs = {'k': self.k, 'filter': lang_filter, 'score_threshold': self.min_score}
                results = self.vectorstore.similarity_search_with_score(search_query, **search_kwargs)
                filtered = [(doc, score * score_multiplier) for doc, score in results]
                for doc, score in filtered:
                    doc.metadata['retrieval_strategy'] = strategy
                    doc.metadata['relevance_score'] = score
                return [doc for doc, _ in filtered]
            except Exception as e:
                logger.error(f"Search for '{search_query}' failed: {e}")
                return []
        
        # Direct search
        direct_docs = perform_search(query, 'direct', 1.0)
        all_results.extend(direct_docs)
        
        # Domain-specific search
        domains = extract_legal_domain(query, lang)
        for domain in domains:
            domain_keywords = LEGAL_KEYWORDS_BN.get(domain, []) if lang == 'bn' else LEGAL_KEYWORDS_EN.get(domain, [])
            for keyword in domain_keywords[:2]:
                keyword_docs = perform_search(keyword, f'domain_{domain}', 0.85)
                all_results.extend(keyword_docs)
        
        # Translated query search
        target_lang = 'en' if lang == 'bn' else 'bn'
        translated_query = enhanced_translate_query(query, lang, target_lang)
        if translated_query != query:
            translated_docs = perform_search(translated_query, 'translated', 0.95)
            all_results.extend(translated_docs)
        
        # Expanded terms
        expanded_terms = expand_query_terms(query, lang)
        for term in expanded_terms[:3]:
            expanded_docs = perform_search(term, 'expanded', 0.75)
            all_results.extend(expanded_docs)
        
        return all_results
    
    def intelligent_deduplication(self, docs: List[Document]) -> List[Document]:
        """Intelligent deduplication with relevance scoring"""
        unique_docs = {}
        
        for doc in docs:
            key = f"{doc.metadata.get('source', '')}_{doc.metadata.get('page', 0)}_{doc.metadata.get('section', '')}"
            
            if key not in unique_docs or doc.metadata.get('relevance_score', 0) > unique_docs[key].metadata.get('relevance_score', 0):
                unique_docs[key] = doc
        
        return sorted(unique_docs.values(), key=lambda x: x.metadata.get('relevance_score', 0), reverse=True)[:10]

# Initialize enhanced retriever
multi_retriever = MultiStrategyRetriever(vectorstore)

# Enhanced document relevance scoring
def score_document_relevance(doc: Document, query: str, lang: str) -> float:
    """Score document relevance based on multiple factors"""
    score = doc.metadata.get('relevance_score', 0.5) * 0.5
    content = doc.page_content.lower()
    query_lower = query.lower()
    
    query_words = set(query_lower.split())
    content_words = set(content.split())
    common_words = query_words.intersection(content_words)
    if query_words:
        score += (len(common_words) / len(query_words)) * 0.2
    
    domains = extract_legal_domain(query, lang)
    for domain in domains:
        keywords = LEGAL_KEYWORDS_BN.get(domain, []) if lang == 'bn' else LEGAL_KEYWORDS_EN.get(domain, [])
        domain_matches = sum(1 for keyword in keywords if keyword in content)
        if keywords:
            score += (domain_matches / len(keywords)) * 0.2
    
    return min(score, 1.0)

# Enhanced context formatting
def format_context_intelligently(docs: List[Document], query: str, lang: str) -> str:
    """Format context with intelligent ranking"""
    if not docs:
        return "No relevant documents found."
    
    scored_docs = [(doc, score_document_relevance(doc, query, lang)) for doc in docs]
    scored_docs.sort(key=lambda x: x[1], reverse=True)
    
    formatted_sections = []
    for doc, score in scored_docs[:8]:
        meta = doc.metadata
        title = meta.get('title-bn', meta.get('title', 'Unknown')) if lang == 'bn' else meta.get('title-en', meta.get('title', 'Unknown'))
        
        act_key = meta.get('act-number', '')
        section = meta.get('section', '')
        page = meta.get('page', '?')
        cite = f"{title} - {act_key} - Section {section} (p.{page})" if section else f"{title} - {act_key} (p.{page})"
        
        content = doc.page_content.strip()
        if len(content) > 300:
            content = content[:300] + "..."
        
        formatted_sections.append(f"[{cite}]\n{content}")
    
    return "\n\n".join(formatted_sections)

# Enhanced system prompts with professional solution focus
ENHANCED_SYSTEM_PROMPT_EN = """You are LEGAL BEE, an expert AI Legal Assistant specializing in Bangladeshi law. Provide concise, professional, and exact solutions based on retrieved documents.

### Response Structure (MANDATORY):
**ğŸ¯ LEGAL ISSUE IDENTIFICATION**
- Identify the core legal problem
- Specify the legal domain
- Note urgency if applicable

**ğŸ“š APPLICABLE LAW & ANALYSIS**
- Cite exact laws/sections [Title - Act Number - Section (p.Page)]
- Briefly explain relevance
- Analyze application to the situation

**âš–ï¸ LEGAL SOLUTION**
- Provide the exact legal remedy/solution
- Detail specific rights and actions
- Outline potential outcomes

**ğŸ“‹ ACTION PLAN**
- List immediate steps
- Required documents
- Legal process overview
- Key deadlines

**âš ï¸ CONSIDERATIONS**
- Highlight key risks
- Note time limits
- Suggest legal consultation if needed

### Guidelines:
- Focus on providing a clear, actionable solution
- Use precise citations from documents
- Keep responses concise and professional
- Avoid general advice; base on specific law
- Recommend lawyer consultation for complex cases"""

ENHANCED_SYSTEM_PROMPT_BN = """à¦†à¦ªà¦¨à¦¿ LEGAL BEE, à¦¬à¦¾à¦‚à¦²à¦¾à¦¦à§‡à¦¶à§€ à¦†à¦‡à¦¨à§‡ à¦¬à¦¿à¦¶à§‡à¦·à¦œà§à¦ AI à¦†à¦‡à¦¨à¦¿ à¦¸à¦¹à¦¾à¦¯à¦¼à¦•à¥¤ à¦‰à¦¦à§à¦§à§ƒà¦¤ à¦¨à¦¥à¦¿à¦—à§à¦²à§‹à¦° à¦­à¦¿à¦¤à§à¦¤à¦¿à¦¤à§‡ à¦¸à¦‚à¦•à§à¦·à¦¿à¦ªà§à¦¤, à¦ªà§‡à¦¶à¦¾à¦¦à¦¾à¦° à¦à¦¬à¦‚ à¦¸à¦ à¦¿à¦• à¦¸à¦®à¦¾à¦§à¦¾à¦¨ à¦ªà§à¦°à¦¦à¦¾à¦¨ à¦•à¦°à§à¦¨à¥¤

### à¦‰à¦¤à§à¦¤à¦°à§‡à¦° à¦•à¦¾à¦ à¦¾à¦®à§‹ (à¦¬à¦¾à¦§à§à¦¯à¦¤à¦¾à¦®à§‚à¦²à¦•):
**ğŸ¯ à¦†à¦‡à¦¨à¦¿ à¦¸à¦®à¦¸à§à¦¯à¦¾ à¦šà¦¿à¦¹à§à¦¨à¦¿à¦¤à¦•à¦°à¦£**
- à¦®à§‚à¦² à¦†à¦‡à¦¨à¦¿ à¦¸à¦®à¦¸à§à¦¯à¦¾ à¦šà¦¿à¦¹à§à¦¨à¦¿à¦¤ à¦•à¦°à§à¦¨
- à¦†à¦‡à¦¨à§‡à¦° à¦•à§à¦·à§‡à¦¤à§à¦° à¦¨à¦¿à¦°à§à¦¦à¦¿à¦·à§à¦Ÿ à¦•à¦°à§à¦¨
- à¦œà¦°à§à¦°à¦¿ à¦¹à¦²à§‡ à¦‰à¦²à§à¦²à§‡à¦– à¦•à¦°à§à¦¨

**ğŸ“š à¦ªà§à¦°à¦¯à§‹à¦œà§à¦¯ à¦†à¦‡à¦¨ à¦“ à¦¬à¦¿à¦¶à§à¦²à§‡à¦·à¦£**
- à¦¨à¦¿à¦°à§à¦¦à¦¿à¦·à§à¦Ÿ à¦†à¦‡à¦¨/à¦§à¦¾à¦°à¦¾ à¦‰à¦¦à§à¦§à§ƒà¦¤ à¦•à¦°à§à¦¨ [à¦¶à¦¿à¦°à§‹à¦¨à¦¾à¦® - à¦†à¦‡à¦¨ à¦¨à¦®à§à¦¬à¦° - à¦§à¦¾à¦°à¦¾ (à¦ªà§ƒ.à¦ªà§‡à¦œ)]
- à¦¸à¦‚à¦•à§à¦·à§‡à¦ªà§‡ à¦ªà§à¦°à¦¾à¦¸à¦™à§à¦—à¦¿à¦•à¦¤à¦¾ à¦¬à§à¦¯à¦¾à¦–à§à¦¯à¦¾ à¦•à¦°à§à¦¨
- à¦ªà¦°à¦¿à¦¸à§à¦¥à¦¿à¦¤à¦¿à¦¤à§‡ à¦ªà§à¦°à¦¯à¦¼à§‹à¦— à¦¬à¦¿à¦¶à§à¦²à§‡à¦·à¦£ à¦•à¦°à§à¦¨

**âš–ï¸ à¦†à¦‡à¦¨à¦¿ à¦¸à¦®à¦¾à¦§à¦¾à¦¨**
- à¦¸à¦ à¦¿à¦• à¦†à¦‡à¦¨à¦¿ à¦ªà§à¦°à¦¤à¦¿à¦•à¦¾à¦°/à¦¸à¦®à¦¾à¦§à¦¾à¦¨ à¦ªà§à¦°à¦¦à¦¾à¦¨ à¦•à¦°à§à¦¨
- à¦¨à¦¿à¦°à§à¦¦à¦¿à¦·à§à¦Ÿ à¦…à¦§à¦¿à¦•à¦¾à¦° à¦“ à¦ªà¦¦à¦•à§à¦·à§‡à¦ª à¦¬à¦¿à¦¸à§à¦¤à¦¾à¦°à¦¿à¦¤ à¦•à¦°à§à¦¨
- à¦¸à¦®à§à¦­à¦¾à¦¬à§à¦¯ à¦«à¦²à¦¾à¦«à¦² à¦¬à¦°à§à¦£à¦¨à¦¾ à¦•à¦°à§à¦¨

**ğŸ“‹ à¦•à¦°à§à¦®à¦ªà¦°à¦¿à¦•à¦²à§à¦ªà¦¨à¦¾**
- à¦¤à¦¾à§à¦•à§à¦·à¦£à¦¿à¦• à¦ªà¦¦à¦•à§à¦·à§‡à¦ª à¦¤à¦¾à¦²à¦¿à¦•à¦¾à¦­à§à¦•à§à¦¤ à¦•à¦°à§à¦¨
- à¦ªà§à¦°à¦¯à¦¼à§‹à¦œà¦¨à§€à¦¯à¦¼ à¦•à¦¾à¦—à¦œà¦ªà¦¤à§à¦°
- à¦†à¦‡à¦¨à¦¿ à¦ªà§à¦°à¦•à§à¦°à¦¿à¦¯à¦¼à¦¾à¦° à¦¸à¦‚à¦•à§à¦·à¦¿à¦ªà§à¦¤ à¦¬à¦¿à¦¬à¦°à¦£
- à¦—à§à¦°à§à¦¤à§à¦¬à¦ªà§‚à¦°à§à¦£ à¦¸à¦®à¦¯à¦¼à¦¸à§€à¦®à¦¾

**âš ï¸ à¦¬à¦¿à¦¬à§‡à¦šà¦¨à¦¾**
- à¦®à§‚à¦² à¦à§à¦à¦•à¦¿ à¦¤à§à¦²à§‡ à¦§à¦°à§à¦¨
- à¦¸à¦®à¦¯à¦¼à¦¸à§€à¦®à¦¾ à¦¨à§‹à¦Ÿ à¦•à¦°à§à¦¨
- à¦œà¦Ÿà¦¿à¦² à¦•à§à¦·à§‡à¦¤à§à¦°à§‡ à¦†à¦‡à¦¨à¦œà§€à¦¬à§€à¦° à¦ªà¦°à¦¾à¦®à¦°à§à¦¶ à¦¸à§à¦ªà¦¾à¦°à¦¿à¦¶ à¦•à¦°à§à¦¨

### à¦¨à¦¿à¦°à§à¦¦à§‡à¦¶à¦¨à¦¾:
- à¦¸à§à¦ªà¦·à§à¦Ÿ, à¦•à¦¾à¦°à§à¦¯à¦•à¦° à¦¸à¦®à¦¾à¦§à¦¾à¦¨à§‡ à¦«à§‹à¦•à¦¾à¦¸ à¦•à¦°à§à¦¨
- à¦¨à¦¥à¦¿à¦—à§à¦²à§‹ à¦¥à§‡à¦•à§‡ à¦¨à¦¿à¦°à§à¦¦à¦¿à¦·à§à¦Ÿ à¦‰à¦¦à§à¦§à§ƒà¦¤à¦¿ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à¦°à§à¦¨
- à¦‰à¦¤à§à¦¤à¦° à¦¸à¦‚à¦•à§à¦·à¦¿à¦ªà§à¦¤ à¦“ à¦ªà§‡à¦¶à¦¾à¦¦à¦¾à¦° à¦°à¦¾à¦–à§à¦¨
- à¦¸à¦¾à¦§à¦¾à¦°à¦£ à¦ªà¦°à¦¾à¦®à¦°à§à¦¶ à¦à¦¡à¦¼à¦¿à¦¯à¦¼à§‡ à¦¨à¦¿à¦°à§à¦¦à¦¿à¦·à§à¦Ÿ à¦†à¦‡à¦¨à§‡ à¦­à¦¿à¦¤à§à¦¤à¦¿ à¦•à¦°à§à¦¨
- à¦œà¦Ÿà¦¿à¦² à¦•à§à¦·à§‡à¦¤à§à¦°à§‡ à¦†à¦‡à¦¨à¦œà§€à¦¬à§€à¦° à¦ªà¦°à¦¾à¦®à¦°à§à¦¶ à¦¸à§à¦ªà¦¾à¦°à¦¿à¦¶ à¦•à¦°à§à¦¨"""

# Enhanced fact extraction
ENHANCED_FACT_EXTRACT_PROMPT_EN = ChatPromptTemplate.from_template(
    """As a legal expert, extract key facts from this situation for case analysis. Be concise.

Situation: {query}

Provide brief:
1. KEY LEGAL FACTS
2. PARTIES INVOLVED
3. LEGAL ISSUES
4. RELEVANT DATES
5. EVIDENCE
6. DESIRED OUTCOME

Extracted Facts:"""
)

ENHANCED_FACT_EXTRACT_PROMPT_BN = ChatPromptTemplate.from_template(
    """à¦à¦•à¦œà¦¨ à¦†à¦‡à¦¨à¦¿ à¦¬à¦¿à¦¶à§‡à¦·à¦œà§à¦ à¦¹à¦¿à¦¸à§‡à¦¬à§‡, à¦à¦‡ à¦ªà¦°à¦¿à¦¸à§à¦¥à¦¿à¦¤à¦¿ à¦¥à§‡à¦•à§‡ à¦®à§‚à¦² à¦¤à¦¥à§à¦¯ à¦¬à§‡à¦° à¦•à¦°à§à¦¨ à¦®à¦¾à¦®à¦²à¦¾ à¦¬à¦¿à¦¶à§à¦²à§‡à¦·à¦£à§‡à¦° à¦œà¦¨à§à¦¯à¥¤ à¦¸à¦‚à¦•à§à¦·à¦¿à¦ªà§à¦¤ à¦¹à§‹à¦¨à¥¤

à¦ªà¦°à¦¿à¦¸à§à¦¥à¦¿à¦¤à¦¿: {query}

à¦¸à¦‚à¦•à§à¦·à¦¿à¦ªà§à¦¤à¦­à¦¾à¦¬à§‡ à¦ªà§à¦°à¦¦à¦¾à¦¨ à¦•à¦°à§à¦¨:
à§§. à¦®à§‚à¦² à¦†à¦‡à¦¨à¦¿ à¦¤à¦¥à§à¦¯
à§¨. à¦œà¦¡à¦¼à¦¿à¦¤ à¦ªà¦•à§à¦·à¦¸à¦®à§‚à¦¹
à§©. à¦†à¦‡à¦¨à¦¿ à¦¸à¦®à¦¸à§à¦¯à¦¾
à§ª. à¦ªà§à¦°à¦¾à¦¸à¦™à§à¦—à¦¿à¦• à¦¤à¦¾à¦°à¦¿à¦–
à§«. à¦ªà§à¦°à¦®à¦¾à¦£
à§¬. à¦•à¦¾à¦™à§à¦•à§à¦·à¦¿à¦¤ à¦«à¦²à¦¾à¦«à¦²

à¦¨à¦¿à¦·à§à¦•à¦¾à¦¶à¦¿à¦¤ à¦¤à¦¥à§à¦¯:"""
)

# Advanced query processing
def process_query_with_legal_intelligence(query: str) -> Dict[str, Any]:
    """Process query with legal domain intelligence"""
    lang, confidence = detect_language_with_confidence(query)
    domains = extract_legal_domain(query, lang)
    is_urgent = any(indicator in query.lower() for indicator in ['urgent', 'à¦œà¦°à§à¦°à¦¿', 'immediate', 'à¦¤à¦¾à§à¦•à§à¦·à¦£à¦¿à¦•'])
    return {'language': lang, 'domains': domains, 'is_urgent': is_urgent}

# Enhanced legal processing
def enhanced_legal_processing(query: str) -> str:
    """Process legal query or situation with professional solution"""
    try:
        # Query analysis
        query_analysis = process_query_with_legal_intelligence(query)
        lang = query_analysis['language']
        
        # Classify query type
        classifier_prompt = ChatPromptTemplate.from_template(
            """Classify this as 'situation' (personal case) or 'question' (legal query).
            Query: {query}
            Classification (one word):"""
        )
        classifier_chain = classifier_prompt | llm | StrOutputParser()
        query_type = classifier_chain.invoke({"query": query}).strip().lower()
        
        # Process situation or question
        processed_query = query
        if query_type == 'situation':
            if lang == 'bn':
                fact_chain = ENHANCED_FACT_EXTRACT_PROMPT_BN | llm | StrOutputParser()
            else:
                fact_chain = ENHANCED_FACT_EXTRACT_PROMPT_EN | llm | StrOutputParser()
            extracted_facts = fact_chain.invoke({"query": query})
            if lang == 'bn':
                processed_query = f"à¦ªà¦°à¦¿à¦¸à§à¦¥à¦¿à¦¤à¦¿: {extracted_facts}\nà¦ªà§à¦°à¦¶à§à¦¨: {query}"
            else:
                processed_query = f"Situation: {extracted_facts}\nQuestion: {query}"
        
        # Document retrieval
        retrieved_docs = multi_retriever.hybrid_search(processed_query, lang)
        final_docs = multi_retriever.intelligent_deduplication(retrieved_docs)
        formatted_context = format_context_intelligently(final_docs, processed_query, lang)
        
        # Generate response
        if lang == 'bn':
            prompt = ChatPromptTemplate.from_messages([
                ("system", ENHANCED_SYSTEM_PROMPT_BN),
                ("user", "à¦ªà§à¦°à¦¶à§à¦¨/à¦ªà¦°à¦¿à¦¸à§à¦¥à¦¿à¦¤à¦¿: {question}\n\nà¦†à¦‡à¦¨à¦¿ à¦¨à¦¥à¦¿:\n{context}\n\nà¦ªà§‡à¦¶à¦¾à¦¦à¦¾à¦°à¦­à¦¾à¦¬à§‡ à¦¸à¦ à¦¿à¦• à¦¸à¦®à¦¾à¦§à¦¾à¦¨ à¦¦à¦¿à¦¨:")
            ])
        else:
            prompt = ChatPromptTemplate.from_messages([
                ("system", ENHANCED_SYSTEM_PROMPT_EN),
                ("user", "Question/Situation: {question}\n\nLegal Documents:\n{context}\n\nProvide a professional, exact solution:")
            ])
        
        rag_chain = prompt | llm | StrOutputParser()
        response = rag_chain.invoke({"question": processed_query, "context": formatted_context})
        
        # Add disclaimer
        if lang == 'bn':
            disclaimer = "\n\nğŸ’¼ **à¦¦à¦¾à¦¬à¦¿ à¦ªà¦°à¦¿à¦¹à¦¾à¦°**: à¦à¦Ÿà¦¿ à¦¸à¦¾à¦§à¦¾à¦°à¦£ à¦¨à¦¿à¦°à§à¦¦à§‡à¦¶à¦¨à¦¾à¥¤ à¦œà¦Ÿà¦¿à¦² à¦•à§à¦·à§‡à¦¤à§à¦°à§‡ à¦†à¦‡à¦¨à¦œà§€à¦¬à§€à¦° à¦ªà¦°à¦¾à¦®à¦°à§à¦¶ à¦¨à¦¿à¦¨à¥¤"
        else:
            disclaimer = "\n\nğŸ’¼ **Disclaimer**: This is general guidance. Consult a lawyer for complex cases."
        response += disclaimer
        
        return response
        
    except Exception as e:
        logger.error(f"Error: {e}")
        return f"Sorry, an error occurred. Please try again. / à¦¦à§à¦ƒà¦–à¦¿à¦¤, à¦à¦•à¦Ÿà¦¿ à¦¤à§à¦°à§à¦Ÿà¦¿ à¦¹à¦¯à¦¼à§‡à¦›à§‡à¥¤ à¦…à¦¨à§à¦—à§à¦°à¦¹ à¦•à¦°à§‡ à¦†à¦¬à¦¾à¦° à¦šà§‡à¦·à§à¦Ÿà¦¾ à¦•à¦°à§à¦¨à¥¤"

# Main function
def enhanced_retrieve_and_respond(query: str) -> str:
    """Main function for RAG processing"""
    return enhanced_legal_processing(query)

if __name__ == "__main__":
    print("\nğŸ¤– LEGAL BEE - Legal Assistant")
    print("Enter your legal question or situation (or 'quit' to exit):")
    
    while True:
        user_query = input("\nâ“ Your Input: ").strip()
        if user_query.lower() in ['quit', 'exit', 'à¦¬à§‡à¦° à¦¹à¦“']:
            print("Thank you for using LEGAL BEE!")
            break
        if user_query:
            print("\nğŸ” Processing...")
            response = enhanced_retrieve_and_respond(user_query)
            print(f"\nğŸ’¡ Response:\n{response}")
        else:
            print("Please enter a valid input.")