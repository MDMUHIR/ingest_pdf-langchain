import os
import re
from dotenv import load_dotenv
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
from langchain_core.output_parsers import StrOutputParser
from langchain_pinecone import PineconeVectorStore
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_google_genai import ChatGoogleGenerativeAI
from operator import itemgetter
from langdetect import detect, LangDetectException
from typing import List, Dict, Tuple, Set, Any
from langchain_core.documents import Document
from langchain_openai import ChatOpenAI
from pydantic import SecretStr
import logging
from collections import Counter
import numpy as np

load_dotenv()

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# HuggingFace embeddings
emb = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

# Pinecone retriever setup
index_name = os.environ["PINECONE_INDEX_NAME"]
vectorstore = PineconeVectorStore(index_name=index_name, embedding=emb, namespace="_default_")

# OpenRouter LLM
OPENROUTER_API_KEY = os.environ["OPENROUTER_API_KEY"]
llm = ChatOpenAI(
    model="openai/gpt-4o-mini",
    temperature=0,
    api_key=SecretStr(OPENROUTER_API_KEY),
    base_url="https://openrouter.ai/api/v1"
)

# Enhanced language detection with confidence scoring
def detect_language_with_confidence(query: str) -> Tuple[str, float]:
    """Enhanced language detection with confidence scoring"""
    try:
        detected = detect(query)
        bengali_chars = len(re.findall(r'[\u0980-\u09FF]', query))
        english_chars = len(re.findall(r'[a-zA-Z]', query))
        total_chars = bengali_chars + english_chars
        
        if total_chars == 0:
            return 'en', 0.5
        
        bengali_ratio = bengali_chars / total_chars
        english_ratio = english_chars / total_chars
        
        if bengali_ratio > 0.6:
            return 'bn', bengali_ratio
        elif english_ratio > 0.6:
            return 'en', english_ratio
        else:
            return detected, 0.7
    except LangDetectException:
        bengali_chars = len(re.findall(r'[\u0980-\u09FF]', query))
        english_chars = len(re.findall(r'[a-zA-Z]', query))
        if bengali_chars > english_chars:
            return 'bn', 0.6
        else:
            return 'en', 0.6

# Legal domain keyword extraction
LEGAL_KEYWORDS_EN = {
    'criminal': ['murder', 'theft', 'fraud', 'assault', 'criminal', 'police', 'fir', 'charge', 'arrest'],
    'civil': ['contract', 'property', 'land', 'dispute', 'damages', 'civil', 'suit', 'decree'],
    'family': ['marriage', 'divorce', 'custody', 'alimony', 'family', 'wife', 'husband', 'child'],
    'banking': ['bank', 'loan', 'defaulter', 'account', 'deposit', 'credit', 'banking'],
    'election': ['election', 'vote', 'candidate', 'officer', 'commission', 'ballot'],
    'labor': ['worker', 'employee', 'salary', 'wage', 'labor', 'employment', 'job'],
    'cyber': ['internet', 'online', 'digital', 'cyber', 'computer', 'data', 'hacking']
}

LEGAL_KEYWORDS_BN = {
    'criminal': ['‡¶ñ‡ßÅ‡¶®', '‡¶ö‡ßÅ‡¶∞‡¶ø', '‡¶™‡ßç‡¶∞‡¶§‡¶æ‡¶∞‡¶£‡¶æ', '‡¶Ü‡¶ï‡ßç‡¶∞‡¶Æ‡¶£', '‡¶´‡ßå‡¶ú‡¶¶‡¶æ‡¶∞‡¶ø', '‡¶™‡ßÅ‡¶≤‡¶ø‡¶∂', '‡¶Æ‡¶æ‡¶Æ‡¶≤‡¶æ', '‡¶ó‡ßç‡¶∞‡ßá‡¶´‡¶§‡¶æ‡¶∞'],
    'civil': ['‡¶ö‡ßÅ‡¶ï‡ßç‡¶§‡¶ø', '‡¶∏‡¶Æ‡ßç‡¶™‡¶§‡ßç‡¶§‡¶ø', '‡¶ú‡¶Æ‡¶ø', '‡¶¨‡¶ø‡¶∞‡ßã‡¶ß', '‡¶ï‡ßç‡¶∑‡¶§‡¶ø‡¶™‡ßÇ‡¶∞‡¶£', '‡¶¶‡ßá‡¶ì‡¶Ø‡¶º‡¶æ‡¶®‡¶ø', '‡¶Æ‡¶æ‡¶Æ‡¶≤‡¶æ', '‡¶°‡¶ø‡¶ï‡ßç‡¶∞‡¶ø'],
    'family': ['‡¶¨‡¶ø‡¶¨‡¶æ‡¶π', '‡¶§‡¶æ‡¶≤‡¶æ‡¶ï', '‡¶Ö‡¶≠‡¶ø‡¶≠‡¶æ‡¶¨‡¶ï‡¶§‡ßç‡¶¨', '‡¶≠‡¶∞‡¶£‡¶™‡ßã‡¶∑‡¶£', '‡¶™‡¶æ‡¶∞‡¶ø‡¶¨‡¶æ‡¶∞‡¶ø‡¶ï', '‡¶∏‡ßç‡¶§‡ßç‡¶∞‡ßÄ', '‡¶∏‡ßç‡¶¨‡¶æ‡¶Æ‡ßÄ', '‡¶∏‡¶®‡ßç‡¶§‡¶æ‡¶®'],
    'banking': ['‡¶¨‡ßç‡¶Ø‡¶æ‡¶Ç‡¶ï', '‡¶ã‡¶£', '‡¶ñ‡ßá‡¶≤‡¶æ‡¶™‡¶ø', '‡¶Ö‡ßç‡¶Ø‡¶æ‡¶ï‡¶æ‡¶â‡¶®‡ßç‡¶ü', '‡¶Ü‡¶Æ‡¶æ‡¶®‡¶§', '‡¶ã‡¶£', '‡¶¨‡ßç‡¶Ø‡¶æ‡¶Ç‡¶ï‡¶ø‡¶Ç'],
    'election': ['‡¶®‡¶ø‡¶∞‡ßç‡¶¨‡¶æ‡¶ö‡¶®', '‡¶≠‡ßã‡¶ü', '‡¶™‡ßç‡¶∞‡¶æ‡¶∞‡ßç‡¶•‡ßÄ', '‡¶ï‡¶∞‡ßç‡¶Æ‡¶ï‡¶∞‡ßç‡¶§‡¶æ', '‡¶ï‡¶Æ‡¶ø‡¶∂‡¶®', '‡¶¨‡ßç‡¶Ø‡¶æ‡¶≤‡¶ü'],
    'labor': ['‡¶∂‡ßç‡¶∞‡¶Æ‡¶ø‡¶ï', '‡¶ï‡¶∞‡ßç‡¶Æ‡¶ö‡¶æ‡¶∞‡ßÄ', '‡¶¨‡ßá‡¶§‡¶®', '‡¶Æ‡¶ú‡ßÅ‡¶∞‡¶ø', '‡¶∂‡ßç‡¶∞‡¶Æ', '‡¶ö‡¶æ‡¶ï‡¶∞‡¶ø', '‡¶ï‡¶æ‡¶ú'],
    'cyber': ['‡¶á‡¶®‡ßç‡¶ü‡¶æ‡¶∞‡¶®‡ßá‡¶ü', '‡¶Ö‡¶®‡¶≤‡¶æ‡¶á‡¶®', '‡¶°‡¶ø‡¶ú‡¶ø‡¶ü‡¶æ‡¶≤', '‡¶∏‡¶æ‡¶á‡¶¨‡¶æ‡¶∞', '‡¶ï‡¶Æ‡ßç‡¶™‡¶ø‡¶â‡¶ü‡¶æ‡¶∞', '‡¶§‡¶•‡ßç‡¶Ø', '‡¶π‡ßç‡¶Ø‡¶æ‡¶ï‡¶ø‡¶Ç']
}

def extract_legal_domain(query: str, lang: str) -> List[str]:
    """Extract legal domains from query"""
    keywords = LEGAL_KEYWORDS_BN if lang == 'bn' else LEGAL_KEYWORDS_EN
    query_lower = query.lower()
    
    domains = []
    for domain, words in keywords.items():
        if any(word in query_lower for word in words):
            domains.append(domain)
    
    return domains if domains else ['general']

# Advanced query expansion
def expand_query_terms(query: str, lang: str) -> List[str]:
    """Expand query with related legal terms"""
    expansions = []
    domains = extract_legal_domain(query, lang)
    
    for domain in domains:
        if domain in LEGAL_KEYWORDS_EN:
            if lang == 'bn':
                expansions.extend(LEGAL_KEYWORDS_BN.get(domain, [])[:3])
            else:
                expansions.extend(LEGAL_KEYWORDS_EN.get(domain, [])[:3])
    
    return list(set(expansions))

# Enhanced translation with legal context
ENHANCED_TRANSLATE_TO_ENGLISH_PROMPT = ChatPromptTemplate.from_template(
    """You are a legal translation expert. Translate this Bengali legal query to English while preserving all legal nuances and terminology.

Important guidelines:
- Maintain exact legal terms and act names
- Preserve section numbers and references
- Keep the formal legal tone
- Use standard legal English terminology
- Ensure the translation captures the legal intent

Bengali Query: {query}
Legal Domain: {domain}

Precise English Translation:"""
)

ENHANCED_TRANSLATE_TO_BENGALI_PROMPT = ChatPromptTemplate.from_template(
    """You are a legal translation expert. Translate this English legal query to Bengali while preserving all legal nuances and terminology.

Important guidelines:
- Maintain exact legal terms and act names in Bengali or keep English terms where standard
- Preserve section numbers and references
- Keep the formal legal tone
- Use standard Bengali legal terminology
- Ensure the translation captures the legal intent

English Query: {query}
Legal Domain: {domain}

Precise Bengali Translation:"""
)

def enhanced_translate_query(query: str, source_lang: str, target_lang: str) -> str:
    """Enhanced translation with legal domain awareness"""
    if source_lang == target_lang:
        return query
    
    try:
        domains = extract_legal_domain(query, source_lang)
        domain_context = ', '.join(domains)
        
        if target_lang == 'en' and source_lang == 'bn':
            chain = ENHANCED_TRANSLATE_TO_ENGLISH_PROMPT | llm | StrOutputParser()
            return chain.invoke({"query": query, "domain": domain_context}).strip()
        elif target_lang == 'bn' and source_lang == 'en':
            chain = ENHANCED_TRANSLATE_TO_BENGALI_PROMPT | llm | StrOutputParser()
            return chain.invoke({"query": query, "domain": domain_context}).strip()
        else:
            return query
    except Exception as e:
        logger.warning(f"Enhanced translation failed: {e}")
        return query

# Multi-strategy retrieval system
class MultiStrategyRetriever:
    def __init__(self, vectorstore, k=30):
        self.vectorstore = vectorstore
        self.k = k
    
    def hybrid_search(self, query: str, lang: str) -> List[Document]:
        """Hybrid search combining multiple strategies"""
        all_docs = []
        
        # Strategy 1: Direct similarity search
        try:
            direct_docs = self.vectorstore.similarity_search(query, k=self.k)
            for doc in direct_docs:
                doc.metadata['retrieval_strategy'] = 'direct'
                doc.metadata['relevance_score'] = 1.0
            all_docs.extend(direct_docs)
        except Exception as e:
            logger.error(f"Direct search failed: {e}")
        
        # Strategy 2: Domain-specific search
        domains = extract_legal_domain(query, lang)
        for domain in domains:
            domain_keywords = LEGAL_KEYWORDS_BN.get(domain, []) if lang == 'bn' else LEGAL_KEYWORDS_EN.get(domain, [])
            for keyword in domain_keywords[:3]:  # Limit to top 3 keywords
                try:
                    keyword_docs = self.vectorstore.similarity_search(keyword, k=10)
                    for doc in keyword_docs:
                        doc.metadata['retrieval_strategy'] = f'domain_{domain}'
                        doc.metadata['relevance_score'] = 0.7
                    all_docs.extend(keyword_docs)
                except Exception as e:
                    logger.error(f"Domain search for {keyword} failed: {e}")
        
        # Strategy 3: Translated query search
        target_lang = 'en' if lang == 'bn' else 'bn'
        translated_query = enhanced_translate_query(query, lang, target_lang)
        if translated_query != query:
            try:
                translated_docs = self.vectorstore.similarity_search(translated_query, k=self.k)
                for doc in translated_docs:
                    doc.metadata['retrieval_strategy'] = 'translated'
                    doc.metadata['relevance_score'] = 0.9
                all_docs.extend(translated_docs)
            except Exception as e:
                logger.error(f"Translated search failed: {e}")
        
        # Strategy 4: Expanded query search
        expanded_terms = expand_query_terms(query, lang)
        for term in expanded_terms[:5]:  # Limit to top 5 expanded terms
            try:
                expanded_docs = self.vectorstore.similarity_search(term, k=8)
                for doc in expanded_docs:
                    doc.metadata['retrieval_strategy'] = 'expanded'
                    doc.metadata['relevance_score'] = 0.6
                all_docs.extend(expanded_docs)
            except Exception as e:
                logger.error(f"Expanded search for {term} failed: {e}")
        
        return all_docs
    
    def intelligent_deduplication(self, docs: List[Document]) -> List[Document]:
        """Intelligent deduplication with relevance scoring"""
        unique_docs = {}
        
        for doc in docs:
            # Create composite key
            doc_id = doc.metadata.get('doc_id')
            page = doc.metadata.get('page', 0)
            section = doc.metadata.get('section', '')
            act_num = doc.metadata.get('act-number', '')
            
            key = f"{doc_id}_{act_num}_{page}_{section}" if doc_id else f"{hash(doc.page_content[:200])}_{page}_{section}"
            
            if key not in unique_docs:
                unique_docs[key] = doc
            else:
                # Keep the document with higher relevance score
                existing_score = unique_docs[key].metadata.get('relevance_score', 0.5)
                new_score = doc.metadata.get('relevance_score', 0.5)
                if new_score > existing_score:
                    unique_docs[key] = doc
        
        # Sort by relevance score and retrieval strategy priority
        strategy_priority = {
            'direct': 4,
            'translated': 3,
            'domain_': 2,  # Prefix matching for domain strategies
            'expanded': 1
        }
        
        sorted_docs = sorted(
            unique_docs.values(),
            key=lambda x: (
                x.metadata.get('relevance_score', 0),
                max([v for k, v in strategy_priority.items() if x.metadata.get('retrieval_strategy', '').startswith(k)] + [0])
            ),
            reverse=True
        )
        
        return sorted_docs[:25]  # Return top 25 most relevant documents

# Initialize enhanced retriever
multi_retriever = MultiStrategyRetriever(vectorstore)

# Enhanced document relevance scoring
def score_document_relevance(doc: Document, query: str, lang: str) -> float:
    """Score document relevance based on multiple factors"""
    score = 0.0
    content = doc.page_content.lower()
    query_lower = query.lower()
    
    # Direct query term matching
    query_words = set(query_lower.split())
    content_words = set(content.split())
    common_words = query_words.intersection(content_words)
    if query_words:
        score += (len(common_words) / len(query_words)) * 0.4
    
    # Legal domain relevance
    domains = extract_legal_domain(query, lang)
    for domain in domains:
        keywords = LEGAL_KEYWORDS_BN.get(domain, []) if lang == 'bn' else LEGAL_KEYWORDS_EN.get(domain, [])
        domain_matches = sum(1 for keyword in keywords if keyword in content)
        if keywords:
            score += (domain_matches / len(keywords)) * 0.3
    
    # Metadata quality scoring
    metadata = doc.metadata
    if metadata.get('section'):
        score += 0.1
    if metadata.get('act-number'):
        score += 0.1
    if metadata.get('title'):
        score += 0.1
    
    return min(score, 1.0)

# Enhanced context formatting with intelligent ranking
def format_context_intelligently(docs: List[Document], query: str, lang: str) -> str:
    """Format context with intelligent ranking and relevance scoring"""
    if not docs:
        return "No relevant documents found."
    
    # Score and rank documents
    scored_docs = []
    for doc in docs:
        relevance_score = score_document_relevance(doc, query, lang)
        doc.metadata['computed_relevance'] = relevance_score
        scored_docs.append((doc, relevance_score))
    
    # Sort by computed relevance
    scored_docs.sort(key=lambda x: x[1], reverse=True)
    
    # Group by act/law for better organization
    grouped_docs = {}
    for doc, score in scored_docs[:20]:  # Top 20 most relevant
        act_key = doc.metadata.get('act-number', 'Unknown Act')
        if act_key not in grouped_docs:
            grouped_docs[act_key] = []
        grouped_docs[act_key].append((doc, score))
    
    # Format grouped documents
    formatted_sections = []
    for act_key, doc_list in grouped_docs.items():
        # Sort documents within each act by relevance
        doc_list.sort(key=lambda x: x[1], reverse=True)
        
        act_sections = []
        for doc, score in doc_list[:5]:  # Top 5 per act
            meta = doc.metadata
            
            # Get title in appropriate language
            if lang == 'bn':
                title = meta.get('title-bn', meta.get('title', 'Unknown'))
            else:
                title = meta.get('title-en', meta.get('title', 'Unknown'))
            
            # Format citation
            section = meta.get('section', '')
            page = meta.get('page', '?')
            
            citation_parts = [title]
            if act_key and act_key != 'Unknown Act':
                citation_parts.append(act_key)
            if section:
                citation_parts.append(f"Section {section}")
            citation_parts.append(f"p.{page}")
            citation_parts.append(f"(Relevance: {score:.2f})")
            
            cite = " - ".join(citation_parts)
            
            # Clean and truncate content
            content = doc.page_content.strip()
            if len(content) > 600:
                content = content[:600] + "..."
            
            act_sections.append(f"[{cite}]\n{content}")
        
        if act_sections:
            formatted_sections.append("\n\n".join(act_sections))
    
    return "\n\n--- NEXT ACT ---\n\n".join(formatted_sections)

# Enhanced system prompts with better legal analysis
ENHANCED_SYSTEM_PROMPT_EN = """You are LEGAL BEE, an expert AI Legal Assistant specializing in Bangladeshi Law with advanced legal analysis capabilities.

### Core Expertise:
You have deep knowledge of Bangladeshi legal system including constitutional law, civil law, criminal law, family law, banking law, labor law, cyber law, and administrative law. You understand legal precedents, procedural requirements, and practical implications.

### Response Structure (MANDATORY):
Always structure your response with these exact sections:

**üéØ LEGAL ISSUE IDENTIFICATION**
- Clearly identify the specific legal problem(s)
- Categorize the area of law involved
- Highlight urgency level (if applicable)

**üìö APPLICABLE LAW & ANALYSIS**
- State relevant laws, acts, and sections with precise citations
- Explain what each law means in practical terms
- Analyze how the law applies to the specific situation

**‚öñÔ∏è LEGAL RIGHTS & REMEDIES**
- List specific rights of the person
- Available legal remedies and options
- Potential outcomes and consequences

**üìã STEP-BY-STEP ACTION PLAN**
- Immediate actions to take
- Documentation needed
- Legal procedures to follow
- Timeline considerations

**‚ö†Ô∏è IMPORTANT CONSIDERATIONS**
- Potential challenges or complications
- Time limitations (statute of limitations)
- Costs and practical considerations
- When to seek urgent legal help

### Quality Standards:
- Base EVERY legal statement on retrieved documents with proper citations [Title - Act Number - Section (p.Page)]
- Provide specific section numbers, not general references
- Explain legal concepts in plain English while maintaining accuracy
- Give practical, actionable advice within Bangladeshi legal framework
- Address potential counterarguments or complications
- Be comprehensive but concise

### Limitations:
- State clearly when information is insufficient
- Recommend consultation with qualified lawyers for complex matters
- Never guarantee legal outcomes
- Stay strictly within Bangladeshi law"""

ENHANCED_SYSTEM_PROMPT_BN = """‡¶Ü‡¶™‡¶®‡¶ø LEGAL BEE, ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂‡ßÄ ‡¶Ü‡¶á‡¶®‡ßá ‡¶¨‡¶ø‡¶∂‡ßá‡¶∑‡¶ú‡ßç‡¶û ‡¶è‡¶ï‡¶ú‡¶® ‡¶¶‡¶ï‡ßç‡¶∑ AI ‡¶Ü‡¶á‡¶®‡¶ø ‡¶∏‡¶π‡¶æ‡¶Ø‡¶º‡¶ï ‡¶Ø‡¶ø‡¶®‡¶ø ‡¶â‡¶®‡ßç‡¶®‡¶§ ‡¶Ü‡¶á‡¶®‡¶ø ‡¶¨‡¶ø‡¶∂‡ßç‡¶≤‡ßá‡¶∑‡¶£‡ßá‡¶∞ ‡¶ï‡ßç‡¶∑‡¶Æ‡¶§‡¶æ ‡¶∞‡¶æ‡¶ñ‡ßá‡¶®‡•§

### ‡¶Æ‡ßÇ‡¶≤ ‡¶¶‡¶ï‡ßç‡¶∑‡¶§‡¶æ:
‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂‡ßÄ ‡¶Ü‡¶á‡¶®‡¶ø ‡¶¨‡ßç‡¶Ø‡¶¨‡¶∏‡ßç‡¶•‡¶æ‡¶∞ ‡¶ó‡¶≠‡ßÄ‡¶∞ ‡¶ú‡ßç‡¶û‡¶æ‡¶® ‡¶Ü‡¶õ‡ßá ‡¶Ø‡¶æ‡¶∞ ‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá ‡¶∞‡¶Ø‡¶º‡ßá‡¶õ‡ßá ‡¶∏‡¶æ‡¶Ç‡¶¨‡¶ø‡¶ß‡¶æ‡¶®‡¶ø‡¶ï ‡¶Ü‡¶á‡¶®, ‡¶¶‡ßá‡¶ì‡¶Ø‡¶º‡¶æ‡¶®‡¶ø ‡¶Ü‡¶á‡¶®, ‡¶´‡ßå‡¶ú‡¶¶‡¶æ‡¶∞‡¶ø ‡¶Ü‡¶á‡¶®, ‡¶™‡¶æ‡¶∞‡¶ø‡¶¨‡¶æ‡¶∞‡¶ø‡¶ï ‡¶Ü‡¶á‡¶®, ‡¶¨‡ßç‡¶Ø‡¶æ‡¶Ç‡¶ï‡¶ø‡¶Ç ‡¶Ü‡¶á‡¶®, ‡¶∂‡ßç‡¶∞‡¶Æ ‡¶Ü‡¶á‡¶®, ‡¶∏‡¶æ‡¶á‡¶¨‡¶æ‡¶∞ ‡¶Ü‡¶á‡¶® ‡¶è‡¶¨‡¶Ç ‡¶™‡ßç‡¶∞‡¶∂‡¶æ‡¶∏‡¶®‡¶ø‡¶ï ‡¶Ü‡¶á‡¶®‡•§ ‡¶Ü‡¶™‡¶®‡¶ø ‡¶Ü‡¶á‡¶®‡¶ø ‡¶®‡¶ú‡¶ø‡¶∞, ‡¶™‡ßç‡¶∞‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ‡¶ó‡¶§ ‡¶™‡ßç‡¶∞‡¶Ø‡¶º‡ßã‡¶ú‡¶®‡ßÄ‡¶Ø‡¶º‡¶§‡¶æ ‡¶è‡¶¨‡¶Ç ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞‡¶ø‡¶ï ‡¶™‡ßç‡¶∞‡¶≠‡¶æ‡¶¨ ‡¶¨‡ßã‡¶ù‡ßá‡¶®‡•§

### ‡¶â‡¶§‡ßç‡¶§‡¶∞‡ßá‡¶∞ ‡¶ï‡¶æ‡¶†‡¶æ‡¶Æ‡ßã (‡¶¨‡¶æ‡¶ß‡ßç‡¶Ø‡¶§‡¶æ‡¶Æ‡ßÇ‡¶≤‡¶ï):
‡¶∏‡¶∞‡ßç‡¶¨‡¶¶‡¶æ ‡¶è‡¶á ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü ‡¶¨‡¶ø‡¶≠‡¶æ‡¶ó‡¶ó‡ßÅ‡¶≤‡¶ø ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶∏‡¶æ‡¶ú‡¶æ‡¶®:

**üéØ ‡¶Ü‡¶á‡¶®‡¶ø ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶ö‡¶ø‡¶π‡ßç‡¶®‡¶ø‡¶§‡¶ï‡¶∞‡¶£**
- ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü ‡¶Ü‡¶á‡¶®‡¶ø ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ(‡¶ó‡ßÅ‡¶≤‡¶ø) ‡¶∏‡ßç‡¶™‡¶∑‡ßç‡¶ü‡¶≠‡¶æ‡¶¨‡ßá ‡¶ö‡¶ø‡¶π‡ßç‡¶®‡¶ø‡¶§ ‡¶ï‡¶∞‡ßÅ‡¶®
- ‡¶∏‡¶Ç‡¶∂‡ßç‡¶≤‡¶ø‡¶∑‡ßç‡¶ü ‡¶Ü‡¶á‡¶®‡ßá‡¶∞ ‡¶ï‡ßç‡¶∑‡ßá‡¶§‡ßç‡¶∞ ‡¶∂‡ßç‡¶∞‡ßá‡¶£‡ßÄ‡¶¨‡¶¶‡ßç‡¶ß ‡¶ï‡¶∞‡ßÅ‡¶®
- ‡¶ú‡¶∞‡ßÅ‡¶∞‡ßÄ ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞‡¶æ ‡¶§‡ßÅ‡¶≤‡ßá ‡¶ß‡¶∞‡ßÅ‡¶® (‡¶Ø‡¶¶‡¶ø ‡¶™‡ßç‡¶∞‡¶Ø‡ßã‡¶ú‡ßç‡¶Ø ‡¶π‡¶Ø‡¶º)

**üìö ‡¶™‡ßç‡¶∞‡¶Ø‡ßã‡¶ú‡ßç‡¶Ø ‡¶Ü‡¶á‡¶® ‡¶ì ‡¶¨‡¶ø‡¶∂‡ßç‡¶≤‡ßá‡¶∑‡¶£**
- ‡¶∏‡ßÅ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü ‡¶â‡¶¶‡ßç‡¶ß‡ßÉ‡¶§‡¶ø ‡¶∏‡¶π ‡¶™‡ßç‡¶∞‡¶æ‡¶∏‡¶ô‡ßç‡¶ó‡¶ø‡¶ï ‡¶Ü‡¶á‡¶®, ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶ï‡ßç‡¶ü ‡¶è‡¶¨‡¶Ç ‡¶ß‡¶æ‡¶∞‡¶æ‡¶∏‡¶Æ‡ßÇ‡¶π ‡¶â‡¶≤‡ßç‡¶≤‡ßá‡¶ñ ‡¶ï‡¶∞‡ßÅ‡¶®
- ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶Ü‡¶á‡¶®‡ßá‡¶∞ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞‡¶ø‡¶ï ‡¶Ö‡¶∞‡ßç‡¶• ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ñ‡ßç‡¶Ø‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶®
- ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü ‡¶™‡¶∞‡¶ø‡¶∏‡ßç‡¶•‡¶ø‡¶§‡¶ø‡¶§‡ßá ‡¶Ü‡¶á‡¶® ‡¶ï‡ßÄ‡¶≠‡¶æ‡¶¨‡ßá ‡¶™‡ßç‡¶∞‡¶Ø‡¶º‡ßã‡¶ó ‡¶π‡¶Ø‡¶º ‡¶§‡¶æ ‡¶¨‡¶ø‡¶∂‡ßç‡¶≤‡ßá‡¶∑‡¶£ ‡¶ï‡¶∞‡ßÅ‡¶®

**‚öñÔ∏è ‡¶Ü‡¶á‡¶®‡¶ø ‡¶Ö‡¶ß‡¶ø‡¶ï‡¶æ‡¶∞ ‡¶ì ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ï‡¶æ‡¶∞**
- ‡¶¨‡ßç‡¶Ø‡¶ï‡ßç‡¶§‡¶ø‡¶∞ ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü ‡¶Ö‡¶ß‡¶ø‡¶ï‡¶æ‡¶∞‡¶∏‡¶Æ‡ßÇ‡¶π ‡¶§‡¶æ‡¶≤‡¶ø‡¶ï‡¶æ‡¶≠‡ßÅ‡¶ï‡ßç‡¶§ ‡¶ï‡¶∞‡ßÅ‡¶®
- ‡¶â‡¶™‡¶≤‡¶¨‡ßç‡¶ß ‡¶Ü‡¶á‡¶®‡¶ø ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ï‡¶æ‡¶∞ ‡¶ì ‡¶¨‡¶ø‡¶ï‡¶≤‡ßç‡¶™‡¶∏‡¶Æ‡ßÇ‡¶π
- ‡¶∏‡¶Æ‡ßç‡¶≠‡¶æ‡¶¨‡ßç‡¶Ø ‡¶´‡¶≤‡¶æ‡¶´‡¶≤ ‡¶ì ‡¶™‡¶∞‡¶ø‡¶£‡¶§‡¶ø

**üìã ‡¶ß‡¶æ‡¶™‡ßá ‡¶ß‡¶æ‡¶™‡ßá ‡¶ï‡¶∞‡ßç‡¶Æ‡¶™‡¶∞‡¶ø‡¶ï‡¶≤‡ßç‡¶™‡¶®‡¶æ**
- ‡¶§‡¶æ‡ßé‡¶ï‡ßç‡¶∑‡¶£‡¶ø‡¶ï ‡¶ó‡ßç‡¶∞‡¶π‡¶£‡ßÄ‡¶Ø‡¶º ‡¶™‡¶¶‡¶ï‡ßç‡¶∑‡ßá‡¶™
- ‡¶™‡ßç‡¶∞‡¶Ø‡¶º‡ßã‡¶ú‡¶®‡ßÄ‡¶Ø‡¶º ‡¶ï‡¶æ‡¶ó‡¶ú‡¶™‡¶§‡ßç‡¶∞
- ‡¶Ö‡¶®‡ßÅ‡¶∏‡¶∞‡¶£‡ßÄ‡¶Ø‡¶º ‡¶Ü‡¶á‡¶®‡¶ø ‡¶™‡ßç‡¶∞‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ
- ‡¶∏‡¶Æ‡¶Ø‡¶º‡ßá‡¶∞ ‡¶¨‡¶ø‡¶¨‡ßá‡¶ö‡¶®‡¶æ

**‚ö†Ô∏è ‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶¨‡¶ø‡¶¨‡ßá‡¶ö‡¶®‡¶æ**
- ‡¶∏‡¶Æ‡ßç‡¶≠‡¶æ‡¶¨‡ßç‡¶Ø ‡¶ö‡ßç‡¶Ø‡¶æ‡¶≤‡ßá‡¶û‡ßç‡¶ú ‡¶¨‡¶æ ‡¶ú‡¶ü‡¶ø‡¶≤‡¶§‡¶æ
- ‡¶∏‡¶Æ‡¶Ø‡¶º‡¶∏‡ßÄ‡¶Æ‡¶æ (‡¶¶‡¶æ‡¶¨‡¶ø‡¶§‡ßç‡¶Ø‡¶æ‡¶ó‡ßá‡¶∞ ‡¶Ü‡¶á‡¶®)
- ‡¶ñ‡¶∞‡¶ö ‡¶ì ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞‡¶ø‡¶ï ‡¶¨‡¶ø‡¶¨‡ßá‡¶ö‡¶®‡¶æ
- ‡¶ï‡¶ñ‡¶® ‡¶ú‡¶∞‡ßÅ‡¶∞‡¶ø ‡¶Ü‡¶á‡¶®‡¶ø ‡¶∏‡¶π‡¶æ‡¶Ø‡¶º‡¶§‡¶æ ‡¶®‡¶ø‡¶§‡ßá ‡¶π‡¶¨‡ßá

### ‡¶ó‡ßÅ‡¶£‡¶Æ‡¶æ‡¶®‡ßá‡¶∞ ‡¶Æ‡¶æ‡¶®:
- ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶Ü‡¶á‡¶®‡¶ø ‡¶¨‡¶ï‡ßç‡¶§‡¶¨‡ßç‡¶Ø ‡¶â‡¶¶‡ßç‡¶ß‡ßÉ‡¶§ ‡¶®‡¶•‡¶ø‡¶™‡¶§‡ßç‡¶∞‡ßá‡¶∞ ‡¶â‡¶™‡¶∞ ‡¶≠‡¶ø‡¶§‡ßç‡¶§‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶® ‡¶∏‡¶†‡¶ø‡¶ï ‡¶â‡¶¶‡ßç‡¶ß‡ßÉ‡¶§‡¶ø ‡¶∏‡¶π [‡¶∂‡¶ø‡¶∞‡ßã‡¶®‡¶æ‡¶Æ - ‡¶Ü‡¶á‡¶® ‡¶®‡¶Æ‡ßç‡¶¨‡¶∞ - ‡¶ß‡¶æ‡¶∞‡¶æ (‡¶™‡ßÉ.‡¶™‡ßá‡¶ú)]
- ‡¶∏‡¶æ‡¶ß‡¶æ‡¶∞‡¶£ ‡¶∞‡ßá‡¶´‡¶æ‡¶∞‡ßá‡¶®‡ßç‡¶∏ ‡¶®‡¶Ø‡¶º, ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü ‡¶ß‡¶æ‡¶∞‡¶æ ‡¶®‡¶Æ‡ßç‡¶¨‡¶∞ ‡¶™‡ßç‡¶∞‡¶¶‡¶æ‡¶® ‡¶ï‡¶∞‡ßÅ‡¶®
- ‡¶®‡¶ø‡¶∞‡ßç‡¶≠‡ßÅ‡¶≤‡¶§‡¶æ ‡¶¨‡¶ú‡¶æ‡¶Ø‡¶º ‡¶∞‡ßá‡¶ñ‡ßá ‡¶∏‡¶π‡¶ú ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶Ø‡¶º ‡¶Ü‡¶á‡¶®‡¶ø ‡¶ß‡¶æ‡¶∞‡¶£‡¶æ ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ñ‡ßç‡¶Ø‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶®
- ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂‡ßÄ ‡¶Ü‡¶á‡¶®‡¶ø ‡¶ï‡¶æ‡¶†‡¶æ‡¶Æ‡ßã‡¶∞ ‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞‡¶ø‡¶ï, ‡¶ï‡¶æ‡¶∞‡ßç‡¶Ø‡¶ï‡¶∞ ‡¶™‡¶∞‡¶æ‡¶Æ‡¶∞‡ßç‡¶∂ ‡¶¶‡¶ø‡¶®
- ‡¶∏‡¶Æ‡ßç‡¶≠‡¶æ‡¶¨‡ßç‡¶Ø ‡¶™‡¶æ‡¶≤‡ßç‡¶ü‡¶æ ‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§‡¶ø ‡¶¨‡¶æ ‡¶ú‡¶ü‡¶ø‡¶≤‡¶§‡¶æ‡¶∞ ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶® ‡¶ï‡¶∞‡ßÅ‡¶®
- ‡¶¨‡ßç‡¶Ø‡¶æ‡¶™‡¶ï ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶∏‡¶Ç‡¶ï‡ßç‡¶∑‡¶ø‡¶™‡ßç‡¶§ ‡¶π‡ßã‡¶®

### ‡¶∏‡ßÄ‡¶Æ‡¶æ‡¶¨‡¶¶‡ßç‡¶ß‡¶§‡¶æ:
- ‡¶§‡¶•‡ßç‡¶Ø ‡¶Ö‡¶™‡¶∞‡ßç‡¶Ø‡¶æ‡¶™‡ßç‡¶§ ‡¶π‡¶≤‡ßá ‡¶∏‡ßç‡¶™‡¶∑‡ßç‡¶ü‡¶≠‡¶æ‡¶¨‡ßá ‡¶â‡¶≤‡ßç‡¶≤‡ßá‡¶ñ ‡¶ï‡¶∞‡ßÅ‡¶®
- ‡¶ú‡¶ü‡¶ø‡¶≤ ‡¶¨‡¶ø‡¶∑‡¶Ø‡¶º‡ßá ‡¶Ø‡ßã‡¶ó‡ßç‡¶Ø ‡¶Ü‡¶á‡¶®‡¶ú‡ßÄ‡¶¨‡ßÄ‡¶¶‡ßá‡¶∞ ‡¶™‡¶∞‡¶æ‡¶Æ‡¶∞‡ßç‡¶∂‡ßá‡¶∞ ‡¶∏‡ßÅ‡¶™‡¶æ‡¶∞‡¶ø‡¶∂ ‡¶ï‡¶∞‡ßÅ‡¶®
- ‡¶Ü‡¶á‡¶®‡¶ø ‡¶´‡¶≤‡¶æ‡¶´‡¶≤‡ßá‡¶∞ ‡¶ó‡ßç‡¶Ø‡¶æ‡¶∞‡¶æ‡¶®‡ßç‡¶ü‡¶ø ‡¶¶‡ßá‡¶¨‡ßá‡¶® ‡¶®‡¶æ
- ‡¶ï‡¶†‡ßã‡¶∞‡¶≠‡¶æ‡¶¨‡ßá ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂‡ßÄ ‡¶Ü‡¶á‡¶®‡ßá‡¶∞ ‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá ‡¶∏‡ßÄ‡¶Æ‡¶æ‡¶¨‡¶¶‡ßç‡¶ß ‡¶•‡¶æ‡¶ï‡ßÅ‡¶®"""

# Enhanced fact extraction with legal categorization
ENHANCED_FACT_EXTRACT_PROMPT_EN = ChatPromptTemplate.from_template(
    """As a legal expert, extract and categorize the key facts from this personal legal situation. Focus on legally relevant elements that would be important for case analysis.

Personal Story: {query}

Please provide:
1. KEY LEGAL FACTS (chronological order)
2. PARTIES INVOLVED (plaintiff, defendant, witnesses, etc.)
3. LEGAL ISSUES IDENTIFIED
4. RELEVANT DATES AND DEADLINES
5. EVIDENCE MENTIONED
6. DESIRED OUTCOME/RELIEF

Extracted Legal Analysis:"""
)

ENHANCED_FACT_EXTRACT_PROMPT_BN = ChatPromptTemplate.from_template(
    """‡¶è‡¶ï‡¶ú‡¶® ‡¶Ü‡¶á‡¶®‡¶ø ‡¶¨‡¶ø‡¶∂‡ßá‡¶∑‡¶ú‡ßç‡¶û ‡¶π‡¶ø‡¶∏‡ßá‡¶¨‡ßá, ‡¶è‡¶á ‡¶¨‡ßç‡¶Ø‡¶ï‡ßç‡¶§‡¶ø‡¶ó‡¶§ ‡¶Ü‡¶á‡¶®‡¶ø ‡¶™‡¶∞‡¶ø‡¶∏‡ßç‡¶•‡¶ø‡¶§‡¶ø ‡¶•‡ßá‡¶ï‡ßá ‡¶Æ‡ßÇ‡¶≤ ‡¶§‡¶•‡ßç‡¶Ø‡¶ó‡ßÅ‡¶≤‡¶ø ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶® ‡¶è‡¶¨‡¶Ç ‡¶∂‡ßç‡¶∞‡ßá‡¶£‡ßÄ‡¶¨‡¶¶‡ßç‡¶ß ‡¶ï‡¶∞‡ßÅ‡¶®‡•§ ‡¶Æ‡¶æ‡¶Æ‡¶≤‡¶æ ‡¶¨‡¶ø‡¶∂‡ßç‡¶≤‡ßá‡¶∑‡¶£‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶Ü‡¶á‡¶®‡¶ø‡¶≠‡¶æ‡¶¨‡ßá ‡¶™‡ßç‡¶∞‡¶æ‡¶∏‡¶ô‡ßç‡¶ó‡¶ø‡¶ï ‡¶â‡¶™‡¶æ‡¶¶‡¶æ‡¶®‡¶ó‡ßÅ‡¶≤‡¶ø‡¶§‡ßá ‡¶Æ‡¶®‡ßã‡¶®‡¶ø‡¶¨‡ßá‡¶∂ ‡¶ï‡¶∞‡ßÅ‡¶®‡•§

‡¶¨‡ßç‡¶Ø‡¶ï‡ßç‡¶§‡¶ø‡¶ó‡¶§ ‡¶ò‡¶ü‡¶®‡¶æ: {query}

‡¶Ö‡¶®‡ßÅ‡¶ó‡ßç‡¶∞‡¶π ‡¶ï‡¶∞‡ßá ‡¶™‡ßç‡¶∞‡¶¶‡¶æ‡¶® ‡¶ï‡¶∞‡ßÅ‡¶®:
‡ßß. ‡¶Æ‡ßÇ‡¶≤ ‡¶Ü‡¶á‡¶®‡¶ø ‡¶§‡¶•‡ßç‡¶Ø (‡¶ï‡¶æ‡¶≤‡¶æ‡¶®‡ßÅ‡¶ï‡ßç‡¶∞‡¶Æ‡¶ø‡¶ï ‡¶ï‡ßç‡¶∞‡¶Æ)
‡ß®. ‡¶ú‡¶°‡¶º‡¶ø‡¶§ ‡¶™‡¶ï‡ßç‡¶∑‡¶∏‡¶Æ‡ßÇ‡¶π (‡¶¨‡¶æ‡¶¶‡ßÄ, ‡¶¨‡¶ø‡¶¨‡¶æ‡¶¶‡ßÄ, ‡¶∏‡¶æ‡¶ï‡ßç‡¶∑‡ßÄ ‡¶á‡¶§‡ßç‡¶Ø‡¶æ‡¶¶‡¶ø)
‡ß©. ‡¶ö‡¶ø‡¶π‡ßç‡¶®‡¶ø‡¶§ ‡¶Ü‡¶á‡¶®‡¶ø ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ
‡ß™. ‡¶™‡ßç‡¶∞‡¶æ‡¶∏‡¶ô‡ßç‡¶ó‡¶ø‡¶ï ‡¶§‡¶æ‡¶∞‡¶ø‡¶ñ ‡¶è‡¶¨‡¶Ç ‡¶∏‡¶Æ‡¶Ø‡¶º‡¶∏‡ßÄ‡¶Æ‡¶æ
‡ß´. ‡¶â‡¶≤‡ßç‡¶≤‡ßá‡¶ñ‡¶ø‡¶§ ‡¶™‡ßç‡¶∞‡¶Æ‡¶æ‡¶£
‡ß¨. ‡¶ï‡¶æ‡¶ô‡ßç‡¶ï‡ßç‡¶∑‡¶ø‡¶§ ‡¶´‡¶≤‡¶æ‡¶´‡¶≤/‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ï‡¶æ‡¶∞

‡¶®‡¶ø‡¶∑‡ßç‡¶ï‡¶æ‡¶∂‡¶ø‡¶§ ‡¶Ü‡¶á‡¶®‡¶ø ‡¶¨‡¶ø‡¶∂‡ßç‡¶≤‡ßá‡¶∑‡¶£:"""
)

# Advanced query processing with legal intelligence
def process_query_with_legal_intelligence(query: str) -> Dict[str, Any]:
    """Advanced query processing with legal domain intelligence"""
    lang, confidence = detect_language_with_confidence(query)
    domains = extract_legal_domain(query, lang)
    
    # Classify query complexity
    complexity_indicators = [
        'multiple parties', 'several issues', 'complex', '‡¶¨‡¶ø‡¶≠‡¶ø‡¶®‡ßç‡¶® ‡¶™‡¶ï‡ßç‡¶∑', '‡¶ú‡¶ü‡¶ø‡¶≤',
        'urgent', '‡¶ú‡¶∞‡ßÅ‡¶∞‡¶ø', 'immediate', '‡¶§‡¶æ‡ßé‡¶ï‡ßç‡¶∑‡¶£‡¶ø‡¶ï'
    ]
    is_complex = any(indicator in query.lower() for indicator in complexity_indicators)
    
    # Detect urgency
    urgency_indicators = [
        'urgent', 'emergency', 'immediate', '‡¶ú‡¶∞‡ßÅ‡¶∞‡¶ø', '‡¶§‡¶æ‡ßé‡¶ï‡ßç‡¶∑‡¶£‡¶ø‡¶ï', '‡¶è‡¶ñ‡¶®‡¶á'
    ]
    is_urgent = any(indicator in query.lower() for indicator in urgency_indicators)
    
    return {
        'language': lang,
        'confidence': confidence,
        'domains': domains,
        'is_complex': is_complex,
        'is_urgent': is_urgent,
        'expanded_terms': expand_query_terms(query, lang)
    }

# Enhanced main processing function
def enhanced_legal_processing(query: str) -> str:
    """Enhanced legal processing with multi-step analysis"""
    try:
        # Step 1: Intelligent query analysis
        query_analysis = process_query_with_legal_intelligence(query)
        lang = query_analysis['language']
        
        logger.info(f"Query Analysis: {query_analysis}")
        
        # Step 2: Classify query type with enhanced logic
        classifier_prompt = ChatPromptTemplate.from_template(
            """Analyze this legal query and classify it as:
            - 'story': Personal legal situation requiring fact extraction and analysis
            - 'direct': Direct legal question about laws, procedures, or rights
            - 'research': Research question about legal concepts or comparative analysis
            
            Consider the language, context, and complexity.
            Query: {query}
            Domains: {domains}
            
            Classification (one word only):"""
        )
        
        classifier_chain = classifier_prompt | llm | StrOutputParser()
        query_type = classifier_chain.invoke({
            "query": query,
            "domains": ", ".join(query_analysis['domains'])
        }).strip().lower()
        
        logger.info(f"Query type: {query_type}")
        
        # Step 3: Enhanced fact extraction for story-type queries
        processed_query = query
        if query_type == 'story':
            if lang == 'bn':
                fact_chain = ENHANCED_FACT_EXTRACT_PROMPT_BN | llm | StrOutputParser()
            else:
                fact_chain = ENHANCED_FACT_EXTRACT_PROMPT_EN | llm | StrOutputParser()
            
            extracted_facts = fact_chain.invoke({"query": query})
            
            # Combine extracted facts with original query
            if lang == 'bn':
                processed_query = f"‡¶Ü‡¶á‡¶®‡¶ø ‡¶¨‡¶ø‡¶∂‡ßç‡¶≤‡ßá‡¶∑‡¶£: {extracted_facts}\n\n‡¶Æ‡ßÇ‡¶≤ ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶®: {query}"
            else:
                processed_query = f"Legal Analysis: {extracted_facts}\n\nOriginal Query: {query}"
        
        # Step 4: Multi-strategy document retrieval
        retrieved_docs = multi_retriever.hybrid_search(processed_query, lang)
        logger.info(f"Retrieved {len(retrieved_docs)} documents from hybrid search")
        
        # Step 5: Intelligent deduplication and ranking
        final_docs = multi_retriever.intelligent_deduplication(retrieved_docs)
        logger.info(f"Final documents after deduplication: {len(final_docs)}")
        
        # Step 6: Enhanced context formatting
        formatted_context = format_context_intelligently(final_docs, processed_query, lang)
        
        # Step 7: Generate enhanced response
        if lang == 'bn':
            prompt = ChatPromptTemplate.from_messages([
                ("system", ENHANCED_SYSTEM_PROMPT_BN),
                ("user", "‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶®: {question}\n\n‡¶Ü‡¶á‡¶®‡¶ø ‡¶®‡¶•‡¶ø ‡¶ì ‡¶™‡ßç‡¶∞‡¶∏‡¶ô‡ßç‡¶ó:\n{context}\n\n‡¶¨‡¶ø‡¶∏‡ßç‡¶§‡¶æ‡¶∞‡¶ø‡¶§ ‡¶Ü‡¶á‡¶®‡¶ø ‡¶¨‡¶ø‡¶∂‡ßç‡¶≤‡ßá‡¶∑‡¶£ ‡¶ì ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶® ‡¶™‡ßç‡¶∞‡¶¶‡¶æ‡¶® ‡¶ï‡¶∞‡ßÅ‡¶®:")
            ])
        else:
            prompt = ChatPromptTemplate.from_messages([
                ("system", ENHANCED_SYSTEM_PROMPT_EN),
                ("user", "Question: {question}\n\nLegal Documents & Context:\n{context}\n\nProvide detailed legal analysis and solution:")
            ])
        
        # Step 8: Generate response with enhanced chain
        rag_chain = prompt | llm | StrOutputParser()
        
        response = rag_chain.invoke({
            "question": query,
            "context": formatted_context
        })
        
        # Step 9: Post-process response for quality enhancement
        enhanced_response = post_process_response(response, query_analysis, final_docs)
        
        return enhanced_response
        
    except Exception as e:
        logger.error(f"Error in enhanced_legal_processing: {e}")
        error_msg = (
            f"‡¶¶‡ßÅ‡¶É‡¶ñ‡¶ø‡¶§, ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶™‡ßç‡¶∞‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ‡¶ï‡¶∞‡¶£‡ßá ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá‡•§ ‡¶Ö‡¶®‡ßÅ‡¶ó‡ßç‡¶∞‡¶π ‡¶ï‡¶∞‡ßá ‡¶Ü‡¶¨‡¶æ‡¶∞ ‡¶ö‡ßá‡¶∑‡ßç‡¶ü‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶®‡•§\n‡¶§‡ßç‡¶∞‡ßÅ‡¶ü‡¶ø: {str(e)}"
            if detect_language_with_confidence(query)[0] == 'bn' else
            f"Sorry, there was an error processing your query. Please try again.\nError: {str(e)}"
        )
        return error_msg

def post_process_response(response: str, query_analysis: Dict, docs: List[Document]) -> str:
    """Post-process response to add quality enhancements"""
    lang = query_analysis['language']
    
    # Add document summary if many documents were used
    if len(docs) > 10:
        if lang == 'bn':
            doc_summary = f"\n\nüìä **‡¶®‡¶•‡¶ø ‡¶∏‡¶æ‡¶∞‡¶æ‡¶Ç‡¶∂**: ‡¶è‡¶á ‡¶â‡¶§‡ßç‡¶§‡¶∞‡¶ü‡¶ø {len(docs)}‡¶ü‡¶ø ‡¶Ü‡¶á‡¶®‡¶ø ‡¶®‡¶•‡¶ø ‡¶•‡ßá‡¶ï‡ßá ‡¶™‡ßç‡¶∞‡¶æ‡¶™‡ßç‡¶§ ‡¶§‡¶•‡ßç‡¶Ø‡ßá‡¶∞ ‡¶≠‡¶ø‡¶§‡ßç‡¶§‡¶ø‡¶§‡ßá ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá‡•§"
        else:
            doc_summary = f"\n\nüìä **Document Summary**: This response is based on analysis of {len(docs)} legal documents."
        response += doc_summary
    
    # Add urgency notice if urgent query detected
    if query_analysis.get('is_urgent'):
        if lang == 'bn':
            urgency_notice = "\n\nüö® **‡¶ú‡¶∞‡ßÅ‡¶∞‡¶ø ‡¶®‡ßã‡¶ü‡¶ø‡¶∂**: ‡¶è‡¶ü‡¶ø ‡¶è‡¶ï‡¶ü‡¶ø ‡¶ú‡¶∞‡ßÅ‡¶∞‡¶ø ‡¶Ü‡¶á‡¶®‡¶ø ‡¶¨‡¶ø‡¶∑‡¶Ø‡¶º ‡¶¨‡¶≤‡ßá ‡¶Æ‡¶®‡ßá ‡¶π‡¶ö‡ßç‡¶õ‡ßá‡•§ ‡¶Ö‡¶¨‡¶ø‡¶≤‡¶Æ‡ßç‡¶¨‡ßá ‡¶è‡¶ï‡¶ú‡¶® ‡¶Ø‡ßã‡¶ó‡ßç‡¶Ø ‡¶Ü‡¶á‡¶®‡¶ú‡ßÄ‡¶¨‡ßÄ‡¶∞ ‡¶∏‡¶æ‡¶•‡ßá ‡¶Ø‡ßã‡¶ó‡¶æ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶®‡•§"
        else:
            urgency_notice = "\n\nüö® **Urgent Notice**: This appears to be an urgent legal matter. Please contact a qualified lawyer immediately."
        response += urgency_notice
    
    # Add complexity warning if complex query detected
    if query_analysis.get('is_complex'):
        if lang == 'bn':
            complexity_warning = "\n\n‚ö†Ô∏è **‡¶ú‡¶ü‡¶ø‡¶≤‡¶§‡¶æ‡¶∞ ‡¶∏‡¶§‡¶∞‡ßç‡¶ï‡¶§‡¶æ**: ‡¶è‡¶ü‡¶ø ‡¶è‡¶ï‡¶ü‡¶ø ‡¶ú‡¶ü‡¶ø‡¶≤ ‡¶Ü‡¶á‡¶®‡¶ø ‡¶¨‡¶ø‡¶∑‡¶Ø‡¶º‡•§ ‡¶¨‡¶ø‡¶∂‡ßá‡¶∑‡¶ú‡ßç‡¶û ‡¶Ü‡¶á‡¶®‡¶ø ‡¶™‡¶∞‡¶æ‡¶Æ‡¶∞‡ßç‡¶∂ ‡¶Ö‡¶§‡ßç‡¶Ø‡¶®‡ßç‡¶§ ‡¶∏‡ßÅ‡¶™‡¶æ‡¶∞‡¶ø‡¶∂ ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º‡•§"
        else:
            complexity_warning = "\n\n‚ö†Ô∏è **Complexity Warning**: This is a complex legal matter. Expert legal consultation is highly recommended."
        response += complexity_warning
    
    # Add disclaimer
    if lang == 'bn':
        disclaimer = "\n\nüíº **‡¶¶‡¶æ‡¶¨‡¶ø ‡¶™‡¶∞‡¶ø‡¶π‡¶æ‡¶∞**: ‡¶è‡¶á ‡¶§‡¶•‡ßç‡¶Ø ‡¶∂‡ßÅ‡¶ß‡ßÅ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞ ‡¶∏‡¶æ‡¶ß‡¶æ‡¶∞‡¶£ ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡ßá‡¶∂‡¶®‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø‡•§ ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü ‡¶Ü‡¶á‡¶®‡¶ø ‡¶™‡¶∞‡¶æ‡¶Æ‡¶∞‡ßç‡¶∂‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶è‡¶ï‡¶ú‡¶® ‡¶≤‡¶æ‡¶á‡¶∏‡ßá‡¶®‡ßç‡¶∏‡¶™‡ßç‡¶∞‡¶æ‡¶™‡ßç‡¶§ ‡¶Ü‡¶á‡¶®‡¶ú‡ßÄ‡¶¨‡ßÄ‡¶∞ ‡¶∏‡¶æ‡¶•‡ßá ‡¶™‡¶∞‡¶æ‡¶Æ‡¶∞‡ßç‡¶∂ ‡¶ï‡¶∞‡ßÅ‡¶®‡•§"
    else:
        disclaimer = "\n\nüíº **Disclaimer**: This information is for general guidance only. Consult with a licensed lawyer for specific legal advice."
    response += disclaimer
    
    return response

# Enhanced retrieval function for backward compatibility
def enhanced_retrieve_and_respond(query: str) -> str:
    """Main function for enhanced RAG processing"""
    return enhanced_legal_processing(query)

# Quality assessment function
def assess_response_quality(response: str, query: str, docs: List[Document]) -> Dict[str, Any]:
    """Assess the quality of generated response"""
    # Check citation coverage
    citation_count = len(re.findall(r'\[.*?\]', response))
    
    # Check structure completeness
    required_sections_en = ['LEGAL ISSUE', 'APPLICABLE LAW', 'RIGHTS & REMEDIES', 'ACTION PLAN', 'CONSIDERATIONS']
    required_sections_bn = ['‡¶Ü‡¶á‡¶®‡¶ø ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ', '‡¶™‡ßç‡¶∞‡¶Ø‡ßã‡¶ú‡ßç‡¶Ø ‡¶Ü‡¶á‡¶®', '‡¶Ö‡¶ß‡¶ø‡¶ï‡¶æ‡¶∞ ‡¶ì ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ï‡¶æ‡¶∞', '‡¶ï‡¶∞‡ßç‡¶Æ‡¶™‡¶∞‡¶ø‡¶ï‡¶≤‡ßç‡¶™‡¶®‡¶æ', '‡¶¨‡¶ø‡¶¨‡ßá‡¶ö‡¶®‡¶æ']
    
    lang = detect_language_with_confidence(query)[0]
    required_sections = required_sections_bn if lang == 'bn' else required_sections_en
    
    sections_found = sum(1 for section in required_sections if section in response.upper())
    structure_completeness = sections_found / len(required_sections)
    
    return {
        'citation_count': citation_count,
        'document_count': len(docs),
        'structure_completeness': structure_completeness,
        'response_length': len(response.split()),
        'language': lang
    }

# Test function with quality assessment
def comprehensive_test():
    """Comprehensive test with quality assessment"""
    test_queries = [
        {
            'query': "Under the Bank Companies Act, 1991, what legal actions can be taken if a bank refuses to provide loan documents to a borrower?",
            
        },
        {
            'query': "Under the Election Officers (Special Provisions) Act, 1991 of Bangladesh, what legal actions can be taken if an election officer is found to be biased?",
            
        },
       
        {
            'query': "‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂‡ßá‡¶∞ ‡¶®‡¶ø‡¶∞‡ßç‡¶¨‡¶æ‡¶ö‡¶® ‡¶ï‡¶∞‡ßç‡¶Æ‡¶ï‡¶∞‡ßç‡¶§‡¶æ (‡¶¨‡¶ø‡¶∂‡ßá‡¶∑ ‡¶¨‡¶ø‡¶ß‡¶æ‡¶®) ‡¶Ü‡¶á‡¶®, ‡ßß‡ßØ‡ßØ‡ßß ‡¶Ö‡¶®‡ßÅ‡¶∏‡¶æ‡¶∞‡ßá, ‡¶Ø‡¶¶‡¶ø ‡¶ï‡ßã‡¶®‡¶ì ‡¶®‡¶ø‡¶∞‡ßç‡¶¨‡¶æ‡¶ö‡¶® ‡¶ï‡¶∞‡ßç‡¶Æ‡¶ï‡¶∞‡ßç‡¶§‡¶æ ‡¶™‡¶ï‡ßç‡¶∑‡¶™‡¶æ‡¶§‡¶¶‡ßÅ‡¶∑‡ßç‡¶ü ‡¶π‡¶® ‡¶§‡¶¨‡ßá ‡¶ï‡ßÄ ‡¶ï‡ßÄ ‡¶Ü‡¶á‡¶®‡¶ø ‡¶¨‡ßç‡¶Ø‡¶¨‡¶∏‡ßç‡¶•‡¶æ ‡¶®‡ßá‡¶ì‡¶Ø‡¶º‡¶æ ‡¶Ø‡ßá‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá?",
            
        }
    ]
    
    print("üîç COMPREHENSIVE RAG SYSTEM TEST")
    print("=" * 60)
    
    for i, test_case in enumerate(test_queries, 1):
        query = test_case['query']
        print(f"\nüß™ TEST CASE {i}")
        print(f"Query: {query}")
        print("-" * 50)
        
        # Process query
        response = enhanced_retrieve_and_respond(query)
        
        # Assess quality
        # Note: We can't access docs directly from the main function, so we'll simulate
        quality_score = {
            'response_length': len(response.split()),
            'has_citations': '[' in response and ']' in response,
            'has_structure': any(marker in response.upper() for marker in ['üéØ', 'üìö', '‚öñÔ∏è', 'üìã', '‚ö†Ô∏è'])
        }
        
        print(f"üìä Response Quality:")
        print(f"   - Length: {quality_score['response_length']} words")
        print(f"   - Has Citations: {quality_score['has_citations']}")
        print(f"   - Structured Format: {quality_score['has_structure']}")
        
        print(f"\nüí° RESPONSE:")
        print(response)
        print("\n" + "=" * 60)

if __name__ == "__main__":
    # Run comprehensive test
    # comprehensive_test()
    
    # Interactive mode
    print("\nü§ñ LEGAL BEE - Enhanced RAG System")
    print("Type your legal question (or 'quit' to exit):")
    
    while True:
        user_query = input("\n‚ùì Your Question: ").strip()
        if user_query.lower() in ['quit', 'exit', '‡¶¨‡ßá‡¶∞ ‡¶π‡¶ì', '‡¶ö‡¶≤‡ßá ‡¶Ø‡¶æ‡¶ì']:
            print("Thank you for using LEGAL BEE! / LEGAL BEE ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶ß‡¶®‡ßç‡¶Ø‡¶¨‡¶æ‡¶¶!")
            break
        
        if user_query:
            print("\nüîç Processing your query...")
            response = enhanced_retrieve_and_respond(user_query)
            print(f"\nüí° LEGAL BEE's Response:\n{response}")
        else:
            print("Please enter a valid question.")